---
layout: post
title: "A Few Notes on Ordinary Least Squares"
date: 2024-11-16
category: [codes]
excerpt: "Although referred to as simple, its strict assumptions and sensitivity to violations often make it anything but simple."
---
We want to model collectivism (GCI) based on ecological threats (i.e. epidemics) and national wealth (GDP). Let's get the data:
  
```r  
ecodata <- read.csv("https://raw.githubusercontent.com/soheilshapouri/epidemics_collectivism/main/Data%20S2.csv")
```
If we have more predictors than observations, we will switch to regilarized regression. But that is not the case here so we move on to train-test split. 
```r
set.seed(123)  
index <- sample(nrow(ecodata), round(nrow(ecodata)*0.8))  
eco_train <- ecodata[index, ]  
eco_test <- ecodata[-index, ]  
```
Start with a simple linear regression
```r
model1 <- lm(GCI ~ No_Epidemics, data = eco_train)
```
Even for simple linear regression there is a better way to do it, using cross-validation to get more reliable assessment of model performance.  
```r
library(caret)
set.seed(123)
cv_model1 <- train(
  form = GCI ~ No_Epidemics, 
  data = eco_train,
  method = "lm", 
  trControl = trainControl(method = "cv", number = 10)
)
```
Now that we have the model, We can extract its information.
```r
# regression coefficients
coef(cv_model1$finalModel)
#RMSE
sigma(cv_model1$finalModel)
#confidence interval
confint(cv_model1$finalModel)

# and the mode important thing, getting the model summary 
summary(cv_model1$finalModel)
# where Residual standard error is RMSE 
# and R-squared is the amount of variance in response explained by explanatory variable(s)
```
If the goal is inference, very low R-squared tells me this is not a good model. If the goal is prediction, considering the range of reponse "GCI", which is -1.85 to +1.92 RMSE of 0.72 is pretty high.
For both cases, I would add more predcitors to see whether I can explain more variability or lower RMSE.  
```r
cv_model2 <- train(
  form = GCI ~ No_Epidemics + GDP,
  data = eco_train,
  method = "lm",
  trControl = trainControl(method = "cv", number = 10)
)
summary(cv_model2$finalModel)
```
R-squared was increased while RMSE was decreased. We are in the right direction but we should always consider the possibility of interactions.  
```r
cv_model3 <- train(
  form = GCI ~ No_Epidemics + GDP + No_Epidemics:GDP, 
  data = eco_train,
  method = "lm", 
  trControl = trainControl(method = "cv", number = 10)
)
summary(cv_model3$finalModel)
```
A small increase in R2 and a decrease in RMSE is noticed. But before moving further let's create a visualization of model 2. A contour plot for two main effects and predicted GCI. 
```r
grid <- expand.grid(
  No_Epidemics = seq(min(eco_train$No_Epidemics), max(eco_train$No_Epidemics), length.out = 100),
  GDP = seq(min(eco_train$GDP), max(eco_train$GDP), length.out = 100)
)

grid$Predicted_GCI <- predict(cv_model2$finalModel, newdata = grid)

library(ggplot2)

ggplot(grid, aes(x = No_Epidemics, y = GDP, z = Predicted_GCI)) +
  geom_tile(aes(fill = Predicted_GCI)) +
  scale_fill_gradient(low = "#F6BE00", high = "#302D26", name = "Predicted GCI") + # Yellowish gradient
  geom_contour(color = "white", alpha = 0.7) + # Add white contour lines
  labs(
    title = "Main Effects of No_Epidemics and GDP on Predicted GCI",
    x = "No_Epidemics",
    y = "GDP"
  ) +
  theme_minimal(base_size = 14) + # Use a minimal theme
  theme(
    plot.title = element_text(face = "bold", size = 18, hjust = 0.5, color = "#F6BE00"),
    axis.title = element_text(color = "#F6BE00"),
    legend.title = element_text(color = "#F6BE00"),
    legend.text = element_text(color = "#F6BE00")
  )
```
![Contour Plot](https://github.com/soheilshapouri/soheilshapouri.github.io/blob/master/_posts/contour.jpeg)








